{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef8cf6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161571"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 — Raw PDF Extraction (all pages into a single JSON file)\n",
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "import json\n",
    "\n",
    "pdf_path = Path(\"data/julius-caesar.pdf\")\n",
    "out_file = Path(\"data/raw_pages.json\")\n",
    "\n",
    "pages = []\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for i, page in enumerate(pdf.pages, start=1):\n",
    "        text = page.extract_text(x_tolerance=2, y_tolerance=2) or \"\"\n",
    "        pages.append({\"page_num\": i, \"text\": text})\n",
    "\n",
    "out_file.write_text(json.dumps(pages, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a4a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89bbcab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 done: 106 pages processed, first_act_page = 2\n"
     ]
    }
   ],
   "source": [
    "# Step 3 — Page-level Act/Scene detection (header-first assumption) — single cell\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "CLEANED_PAGES = DATA_DIR / \"cleaned_pages.json\"\n",
    "RAW_PAGES = DATA_DIR / \"raw_pages.json\"\n",
    "OUT_FILE = DATA_DIR / \"step3_structured_pages.json\"\n",
    "\n",
    "# choose source: prefer cleaned pages (artifact-removed)\n",
    "if CLEANED_PAGES.exists():\n",
    "    pages = json.loads(CLEANED_PAGES.read_text(encoding=\"utf-8\"))\n",
    "elif RAW_PAGES.exists():\n",
    "    pages = json.loads(RAW_PAGES.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    raise FileNotFoundError(\"No source pages json found. Run extraction (Step 1) first.\")\n",
    "\n",
    "# regex patterns (robust to variants)\n",
    "act_pat = re.compile(r'\\bACT\\b[\\s\\.\\-:]*([IVXLCDM]+|\\d+)\\b', re.IGNORECASE)\n",
    "scene_pat = re.compile(r'\\b(?:SC(?:\\.|ENE)?|SCENE|Scene)\\b[\\s\\.\\-:]*([IVXLCDM]+|\\d+)\\b', re.IGNORECASE)\n",
    "\n",
    "TOP_N_LINES = 12  # only inspect top N lines of each page (header-first assumption)\n",
    "\n",
    "structured = []\n",
    "current_act = None\n",
    "current_scene = None\n",
    "first_act_page = None\n",
    "\n",
    "for pg in pages:\n",
    "    page_num = pg.get(\"page_num\")\n",
    "    text = pg.get(\"clean_text\") or pg.get(\"text\") or \"\"\n",
    "    # get top N non-empty lines\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    top_lines = lines[:TOP_N_LINES]\n",
    "\n",
    "    found_act = None\n",
    "    found_scene = None\n",
    "    heading_lines = []\n",
    "\n",
    "    # scan only the top_lines for ACT/SCENE\n",
    "    for ln in top_lines:\n",
    "        m_act = act_pat.search(ln)\n",
    "        if m_act:\n",
    "            found_act = m_act.group(1).upper()\n",
    "            heading_lines.append(ln)\n",
    "            # do not break yet — a line may also contain scene\n",
    "        m_scene = scene_pat.search(ln)\n",
    "        if m_scene:\n",
    "            found_scene = m_scene.group(1).upper()\n",
    "            heading_lines.append(ln)\n",
    "\n",
    "    # Apply header-first policy:\n",
    "    # - If found_act in top lines -> update current_act and reset scene if not found_scene\n",
    "    # - If found_scene in top lines -> update current_scene\n",
    "    if found_act:\n",
    "        current_act = found_act\n",
    "        if first_act_page is None:\n",
    "            first_act_page = page_num\n",
    "        # if no scene found on same page, current_scene remains None until a scene header appears\n",
    "    if found_scene:\n",
    "        current_scene = found_scene\n",
    "\n",
    "    # Determine flags\n",
    "    is_front_matter = False\n",
    "    if current_act is None:\n",
    "        # still before first act — treat as front matter\n",
    "        is_front_matter = True\n",
    "\n",
    "    # assign page-level metadata (propagate last seen act/scene for play-content pages)\n",
    "    page_entry = {\n",
    "        \"page_num\": page_num,\n",
    "        \"clean_text\": text,\n",
    "        \"act\": current_act if not is_front_matter else None,\n",
    "        \"scene\": current_scene if not is_front_matter else None,\n",
    "        \"heading_lines_top\": heading_lines,\n",
    "        \"is_front_matter\": is_front_matter\n",
    "    }\n",
    "    structured.append(page_entry)\n",
    "\n",
    "# Save step3 output (stable filename)\n",
    "OUT_FILE.write_text(json.dumps(structured, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# minimal print\n",
    "print(f\"Step 3 done: {len(structured)} pages processed, first_act_page = {first_act_page}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c024ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 — Remove Folger artifacts & reconstruct structured blocks -> data/step4.jsonl\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "IN_JSON = DATA_DIR / \"step3_structured_pages.json\"\n",
    "OUT_JSONL = DATA_DIR / \"step4.jsonl\"\n",
    "\n",
    "if not IN_JSON.exists():\n",
    "    raise FileNotFoundError(\"step3_structured_pages.json not found\")\n",
    "\n",
    "pages = json.loads(IN_JSON.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# patterns to remove\n",
    "ftln_pat = re.compile(r'\\bFTLN\\b\\s*\\d{1,4}', re.IGNORECASE)\n",
    "page_header_num_title_pat = re.compile(r'^\\s*\\d+\\s+Julius\\s+Caesar.*$', re.IGNORECASE)\n",
    "page_num_only_pat = re.compile(r'^\\s*(?:Page\\s*)?\\d{1,4}\\s*$', re.IGNORECASE)\n",
    "# speaker detection: lines beginning with UPPERCASE name possibly with numbers/periods, e.g., \"BRUTUS\", \"BRUTUS,\", \"FIRST SOLDIER\"\n",
    "speaker_line_full = re.compile(r'^\\s*([A-Z][A-Z0-9\\-\\s]+?)[\\.:]?\\s*(?:\\s+(.+))?$')\n",
    "# stage directions or entrances\n",
    "stage_dir_pat = re.compile(r'^\\s*(Enter|Exit|Exeunt|SCENE|ACT|Stage|Stage Directions|[A-Z][a-z]+ing)\\b', re.IGNORECASE)\n",
    "\n",
    "records = []\n",
    "block_id = 0\n",
    "\n",
    "def clean_page_text(raw_text):\n",
    "    t = raw_text or \"\"\n",
    "    t = ftln_pat.sub(\"\", t)              # remove FTLN tokens\n",
    "    # remove header/footer lines\n",
    "    lines = [ln.rstrip() for ln in t.splitlines()]\n",
    "    cleaned_lines = []\n",
    "    for ln in lines:\n",
    "        if not ln.strip():\n",
    "            cleaned_lines.append(\"\")  # preserve blank for paragraph boundaries\n",
    "            continue\n",
    "        if page_header_num_title_pat.match(ln):\n",
    "            continue\n",
    "        if page_num_only_pat.fullmatch(ln):\n",
    "            continue\n",
    "        cleaned_lines.append(ln)\n",
    "    # collapse 3+ blanks to 2\n",
    "    out = \"\\n\".join(cleaned_lines)\n",
    "    out = re.sub(r'\\n{3,}', '\\n\\n', out)\n",
    "    return out.strip() + \"\\n\"\n",
    "\n",
    "# iterate pages, build continuous stream of lines with page info\n",
    "line_stream = []  # list of (page_num, line_text)\n",
    "for pg in pages:\n",
    "    pnum = pg.get(\"page_num\")\n",
    "    raw = pg.get(\"clean_text\") or pg.get(\"text\") or \"\"\n",
    "    cleaned = clean_page_text(raw)\n",
    "    for ln in cleaned.splitlines():\n",
    "        line_stream.append((pnum, ln))\n",
    "\n",
    "# now parse line_stream into speaker blocks\n",
    "i = 0\n",
    "n = len(line_stream)\n",
    "current_block = None  # dict with keys: speaker, lines, start_page, end_page, act, scene, block_type\n",
    "\n",
    "while i < n:\n",
    "    pnum, ln = line_stream[i]\n",
    "    if not ln.strip():\n",
    "        # blank line => break current block (if any) and skip\n",
    "        if current_block:\n",
    "            current_block['end_page'] = current_block.get('end_page', pnum)\n",
    "            text = \"\\n\".join(current_block['lines']).strip()\n",
    "            block_type = current_block.get('block_type','speech')\n",
    "            block_id += 1\n",
    "            records.append({\n",
    "                \"block_id\": block_id,\n",
    "                \"act\": current_block.get(\"act\"),\n",
    "                \"scene\": current_block.get(\"scene\"),\n",
    "                \"speaker\": current_block.get(\"speaker\"),\n",
    "                \"text\": text,\n",
    "                \"start_page\": current_block.get(\"start_page\"),\n",
    "                \"end_page\": current_block.get(\"end_page\"),\n",
    "                \"block_type\": block_type\n",
    "            })\n",
    "            current_block = None\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # detect speaker inline\n",
    "    m = speaker_line_full.match(ln)\n",
    "    is_stage = bool(stage_dir_pat.match(ln))\n",
    "    if m and (m.group(1).isupper() or is_stage):\n",
    "        speaker = m.group(1).strip()\n",
    "        rest = (m.group(2) or \"\").strip()\n",
    "        # commit current block if different speaker\n",
    "        if current_block:\n",
    "            # if same speaker, append; else finish and start new\n",
    "            if current_block.get(\"speaker\") == speaker:\n",
    "                if rest:\n",
    "                    current_block['lines'].append(rest)\n",
    "                current_block['end_page'] = pnum\n",
    "            else:\n",
    "                # finish previous\n",
    "                current_block['end_page'] = current_block.get('end_page', pnum)\n",
    "                text = \"\\n\".join(current_block['lines']).strip()\n",
    "                block_type = current_block.get('block_type','speech')\n",
    "                block_id += 1\n",
    "                records.append({\n",
    "                    \"block_id\": block_id,\n",
    "                    \"act\": current_block.get(\"act\"),\n",
    "                    \"scene\": current_block.get(\"scene\"),\n",
    "                    \"speaker\": current_block.get(\"speaker\"),\n",
    "                    \"text\": text,\n",
    "                    \"start_page\": current_block.get(\"start_page\"),\n",
    "                    \"end_page\": current_block.get(\"end_page\"),\n",
    "                    \"block_type\": block_type\n",
    "                })\n",
    "                current_block = None\n",
    "                # start new\n",
    "                current_block = {\n",
    "                    \"speaker\": speaker,\n",
    "                    \"lines\": [rest] if rest else [],\n",
    "                    \"start_page\": pnum,\n",
    "                    \"end_page\": pnum,\n",
    "                    \"act\": None,\n",
    "                    \"scene\": None,\n",
    "                    \"block_type\": \"stage_direction\" if is_stage else \"speech\"\n",
    "                }\n",
    "        else:\n",
    "            # start new block\n",
    "            current_block = {\n",
    "                \"speaker\": speaker,\n",
    "                \"lines\": [rest] if rest else [],\n",
    "                \"start_page\": pnum,\n",
    "                \"end_page\": pnum,\n",
    "                \"act\": None,\n",
    "                \"scene\": None,\n",
    "                \"block_type\": \"stage_direction\" if is_stage else \"speech\"\n",
    "            }\n",
    "        # attach act/scene from nearest page metadata\n",
    "        # find page metadata from pages list (fast lookup)\n",
    "        # build once mapping\n",
    "        i += 1\n",
    "        continue\n",
    "    else:\n",
    "        # line does not start with speaker; treat as continuation of current block if exists\n",
    "        if current_block:\n",
    "            current_block['lines'].append(ln)\n",
    "            current_block['end_page'] = pnum\n",
    "        else:\n",
    "            # orphan line: create an anonymous narrator block (e.g., stage direction or prose)\n",
    "            current_block = {\n",
    "                \"speaker\": None,\n",
    "                \"lines\": [ln],\n",
    "                \"start_page\": pnum,\n",
    "                \"end_page\": pnum,\n",
    "                \"act\": None,\n",
    "                \"scene\": None,\n",
    "                \"block_type\": \"narration\"\n",
    "            }\n",
    "    i += 1\n",
    "\n",
    "# finish last block\n",
    "if current_block:\n",
    "    current_block['end_page'] = current_block.get('end_page')\n",
    "    text = \"\\n\".join(current_block['lines']).strip()\n",
    "    block_type = current_block.get('block_type','speech')\n",
    "    block_id += 1\n",
    "    records.append({\n",
    "        \"block_id\": block_id,\n",
    "        \"act\": current_block.get(\"act\"),\n",
    "        \"scene\": current_block.get(\"scene\"),\n",
    "        \"speaker\": current_block.get(\"speaker\"),\n",
    "        \"text\": text,\n",
    "        \"start_page\": current_block.get(\"start_page\"),\n",
    "        \"end_page\": current_block.get(\"end_page\"),\n",
    "        \"block_type\": block_type\n",
    "    })\n",
    "\n",
    "# attach act/scene metadata to records by looking up pages mapping (closest start_page)\n",
    "page_meta = { p['page_num']: p for p in pages }\n",
    "for r in records:\n",
    "    sp = r.get(\"start_page\")\n",
    "    meta = page_meta.get(sp) or {}\n",
    "    r['act'] = meta.get('act')\n",
    "    r['scene'] = meta.get('scene')\n",
    "\n",
    "# merge very short speaker fragments into previous block if same speaker to fix table splits\n",
    "merged = []\n",
    "for r in records:\n",
    "    if merged and r['speaker'] == merged[-1]['speaker'] and len(r['text'].split()) < 6:\n",
    "        # merge\n",
    "        merged[-1]['text'] = merged[-1]['text'] + \"\\n \" + r['text']\n",
    "        merged[-1]['end_page'] = r['end_page']\n",
    "    else:\n",
    "        merged.append(r)\n",
    "\n",
    "# write to JSONL\n",
    "with OUT_JSONL.open('w', encoding='utf-8') as f:\n",
    "    for r in merged:\n",
    "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd5746f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 done: 854 blocks -> data/step5.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Step 5 — Merge continuations & isolate stage directions -> data/step5.jsonl\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "IN_FILE = DATA_DIR / \"step4.jsonl\"\n",
    "OUT_FILE = DATA_DIR / \"step5.jsonl\"\n",
    "\n",
    "if not IN_FILE.exists():\n",
    "    raise FileNotFoundError(\"data/step4.jsonl not found. Run Step 4 first.\")\n",
    "\n",
    "# Load records\n",
    "with IN_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    recs = [json.loads(line) for line in f.read().splitlines() if line.strip()]\n",
    "\n",
    "# Helpers\n",
    "stage_dir_pat = re.compile(\n",
    "    r'^\\s*(Enter|Exit|Exeunt|Exit,|Enter,|Exeunt,|[Tt]he\\s+[A-Z][a-z]+\\s+(comes|comes forward|comes on|enters|appears)|\\[|{).*$',\n",
    "    re.IGNORECASE)\n",
    "act_scene_pat = re.compile(r'^\\s*ACT\\b|^\\s*SC(?:\\.|ENE)?\\b', re.IGNORECASE)\n",
    "speaker_heading_pat = re.compile(r'^[A-Z][A-Z0-9\\-\\s]+$')  # loose check for \"BRUTUS\", \"FIRST SOLDIER\"\n",
    "\n",
    "def is_stage_direction_text(txt):\n",
    "    if not txt or not isinstance(txt, str):\n",
    "        return False\n",
    "    txts = txt.strip()\n",
    "    if not txts:\n",
    "        return False\n",
    "    # start with \"The Soothsayer comes forward.\" or \"Enter ...\" or bracketed directions\n",
    "    if stage_dir_pat.match(txts):\n",
    "        return True\n",
    "    # short parenthetical directions e.g., \"(Aside)\" or \"(to Antony)\"\n",
    "    if txts.startswith(\"(\") and txts.endswith(\")\"):\n",
    "        return True\n",
    "    # lines that are short and capitalized but are not full-sentence speeches\n",
    "    if len(txts.split()) <= 5 and txts[0].isupper() and txts.endswith(\".\"):\n",
    "        # likely a stage direction (e.g., \"Sennet.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_whitespace(s):\n",
    "    return re.sub(r'\\s+\\n', '\\n', (s or \"\")).strip()\n",
    "\n",
    "# Merge pass\n",
    "merged = []\n",
    "for r in recs:\n",
    "    # normalize fields\n",
    "    r['speaker'] = None if r.get('speaker') in (None, \"None\", \"\") else r.get('speaker')\n",
    "    r['text'] = (r.get('text') or \"\").strip()\n",
    "    r['start_page'] = int(r.get('start_page') or 0)\n",
    "    r['end_page'] = int(r.get('end_page') or r['start_page'])\n",
    "    # classify stage direction if detected in speaker or text\n",
    "    if r['speaker'] and is_stage_direction_text(r['speaker']):\n",
    "        r['block_type'] = 'stage_direction'\n",
    "        r['speaker'] = None\n",
    "    elif is_stage_direction_text(r['text']):\n",
    "        r['block_type'] = 'stage_direction'\n",
    "        # keep speaker if valid, else none\n",
    "        if not r['speaker']:\n",
    "            r['speaker'] = None\n",
    "    merged.append(r)\n",
    "\n",
    "# Now merge continuations into previous block when safe\n",
    "out = []\n",
    "for idx, cur in enumerate(merged):\n",
    "    if not out:\n",
    "        out.append(cur)\n",
    "        continue\n",
    "    prev = out[-1]\n",
    "\n",
    "    # Conditions to merge cur into prev:\n",
    "    # 1) cur has no speaker (or speaker is None) AND prev has a speaker\n",
    "    # 2) pages are same or consecutive (allow prev.end_page == cur.start_page or +1)\n",
    "    # 3) cur is not a clear stage direction or ACT/SCENE heading or scene-break\n",
    "    cond_pages = (cur['start_page'] == prev['end_page']) or (cur['start_page'] == prev['end_page'] + 1)\n",
    "    cur_is_orphan = not cur.get('speaker')\n",
    "    cur_is_stage = (cur.get('block_type') == 'stage_direction') or is_stage_direction_text(cur.get('text', \"\"))\n",
    "    cur_is_act_scene = bool(act_scene_pat.search(cur.get('text', \"\")[:40]))\n",
    "\n",
    "    if cur_is_orphan and prev.get('speaker') and cond_pages and (not cur_is_stage) and (not cur_is_act_scene):\n",
    "        # Hyphenation fix: if prev ends with hyphenated token, join directly\n",
    "        prev_text = prev.get('text', \"\")\n",
    "        cur_text = cur.get('text', \"\")\n",
    "        if prev_text.rstrip().endswith(\"-\"):\n",
    "            # remove hyphen and join without space\n",
    "            prev['text'] = prev_text.rstrip()[:-1] + cur_text.lstrip()\n",
    "        else:\n",
    "            prev['text'] = prev_text.rstrip() + \"\\n\" + cur_text.lstrip()\n",
    "        prev['end_page'] = max(prev.get('end_page', prev.get('start_page')), cur.get('end_page', cur.get('start_page')))\n",
    "        # keep prev.block_type as speech\n",
    "        continue\n",
    "    else:\n",
    "        # small heuristic: if cur has speaker but it's identical to prev.speaker merge\n",
    "        if cur.get('speaker') and prev.get('speaker') and cur.get('speaker') == prev.get('speaker'):\n",
    "            # also allow merge if cur is very short (<6 words)\n",
    "            if len(cur.get('text','').split()) < 6:\n",
    "                prev['text'] = prev.get('text','').rstrip() + \"\\n\" + cur.get('text','').lstrip()\n",
    "                prev['end_page'] = max(prev.get('end_page', prev.get('start_page')), cur.get('end_page', cur.get('start_page')))\n",
    "                continue\n",
    "        out.append(cur)\n",
    "\n",
    "# Final pass: attach orphan initial blocks (before first speaker) to next speaker if appropriate\n",
    "final = []\n",
    "i = 0\n",
    "while i < len(out):\n",
    "    r = out[i]\n",
    "    if i == 0 and (not r.get('speaker')) and len(out) > 1:\n",
    "        # if first block is orphan and next block has speaker, merge into next if orphan is short and not stage\n",
    "        nxt = out[1]\n",
    "        orphan_word_count = len((r.get('text') or \"\").split())\n",
    "        if orphan_word_count <= 8 and not is_stage_direction_text(r.get('text','')):\n",
    "            # merge into nxt (prepend)\n",
    "            nxt['text'] = r.get('text','').rstrip() + \"\\n\" + nxt.get('text','')\n",
    "            nxt['start_page'] = min(nxt.get('start_page',9999), r.get('start_page',9999))\n",
    "            i += 1\n",
    "            continue\n",
    "    final.append(r)\n",
    "    i += 1\n",
    "\n",
    "# Save to step5.jsonl\n",
    "with OUT_FILE.open('w', encoding='utf-8') as f:\n",
    "    for rec in final:\n",
    "        # clean whitespace small\n",
    "        rec['text'] = clean_whitespace(rec.get('text',''))\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Step 5 done:\", len(final), \"blocks -> data/step5.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "457bb991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done → data\\step6.jsonl (total chunks = 871)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Add metadata → produce final RAG-ready chunks\n",
    "# Input:  data/step5.jsonl\n",
    "# Output: data/step6.jsonl\n",
    "# RULE: SPEAKER IS NEVER MODIFIED.\n",
    "\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"data\")\n",
    "IN_PATH = DATA / \"step5.jsonl\"\n",
    "OUT_PATH = DATA / \"step6.jsonl\"\n",
    "\n",
    "if not IN_PATH.exists():\n",
    "    raise FileNotFoundError(\"step5.jsonl not found in /data folder\")\n",
    "\n",
    "# Roman → int mapping\n",
    "roman_map = {\n",
    "    'I':1,'II':2,'III':3,'IV':4,'V':5,'VI':6,'VII':7,'VIII':8,'IX':9,'X':10,\n",
    "    'XI':11,'XII':12,'XIII':13,'XIV':14,'XV':15\n",
    "}\n",
    "\n",
    "def roman_to_int(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = str(s).strip().upper()\n",
    "    if s.isdigit():\n",
    "        return int(s)\n",
    "    return roman_map.get(s)\n",
    "\n",
    "# -------------------------\n",
    "# LOAD BLOCKS (exactly as-is)\n",
    "# -------------------------\n",
    "blocks = []\n",
    "with IN_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        rec = json.loads(line)\n",
    "\n",
    "        # do NOT modify speaker\n",
    "        text = (rec.get(\"text\") or \"\").strip()\n",
    "\n",
    "        # Normalize metadata, but DO NOT TOUCH SPEAKER\n",
    "        block = {\n",
    "            \"block_type\": rec.get(\"block_type\"),\n",
    "            \"speaker\": rec.get(\"speaker\"),          # keep EXACT value\n",
    "            \"text\": text,\n",
    "            \"act_raw\": rec.get(\"act\"),\n",
    "            \"scene_raw\": rec.get(\"scene\"),\n",
    "            \"act\": roman_to_int(rec.get(\"act\")),\n",
    "            \"scene\": roman_to_int(rec.get(\"scene\")),\n",
    "            \"start_page\": int(rec.get(\"start_page\") or 0),\n",
    "            \"end_page\": int(rec.get(\"end_page\") or rec.get(\"start_page\") or 0)\n",
    "        }\n",
    "\n",
    "        block[\"word_count\"] = len(block[\"text\"].split())\n",
    "        blocks.append(block)\n",
    "\n",
    "# Sort blocks for consistent chunking\n",
    "blocks = sorted(blocks, key=lambda b: (b[\"act\"] or 0, b[\"scene\"] or 0, b[\"start_page\"], b[\"end_page\"]))\n",
    "\n",
    "# -------------------------\n",
    "# GROUP BY SCENE\n",
    "# -------------------------\n",
    "scene_groups = {}\n",
    "for b in blocks:\n",
    "    key = (b[\"act\"], b[\"scene\"])\n",
    "    if key == (None, None):\n",
    "        continue\n",
    "    scene_groups.setdefault(key, []).append(b)\n",
    "\n",
    "# -------------------------\n",
    "# BUILD CHUNKS\n",
    "# -------------------------\n",
    "chunks = []\n",
    "chunk_id = 0\n",
    "\n",
    "# ---- SCENE CHUNKS ----\n",
    "for (act, scene), items in scene_groups.items():\n",
    "    scene_text = \"\\n\\n\".join([x[\"text\"] for x in items if x[\"text\"]])\n",
    "\n",
    "    chunk_id += 1\n",
    "    chunks.append({\n",
    "        \"chunk_id\": chunk_id,\n",
    "        \"chunk_type\": \"scene\",\n",
    "        \"act\": act,\n",
    "        \"scene\": scene,\n",
    "        \"start_page\": min(x[\"start_page\"] for x in items),\n",
    "        \"end_page\": max(x[\"end_page\"] for x in items),\n",
    "        \"text\": scene_text,\n",
    "        \"word_count\": len(scene_text.split()),\n",
    "        \"speakers\": sorted(set(x[\"speaker\"] for x in items if x.get(\"speaker\")))\n",
    "    })\n",
    "\n",
    "# ---- SPEECH/STAGE CHUNKS ----\n",
    "for b in blocks:\n",
    "\n",
    "    # Stage direction → separate chunk\n",
    "    if b[\"block_type\"] == \"stage_direction\":\n",
    "        chunk_id += 1\n",
    "        chunks.append({\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"chunk_type\": \"stage_direction\",\n",
    "            \"act\": b[\"act\"],\n",
    "            \"scene\": b[\"scene\"],\n",
    "            \"speaker\": b[\"speaker\"],              # unchanged\n",
    "            \"text\": b[\"text\"],\n",
    "            \"start_page\": b[\"start_page\"],\n",
    "            \"end_page\": b[\"end_page\"],\n",
    "            \"word_count\": b[\"word_count\"],\n",
    "            \"is_soliloquy\": False\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Speech block\n",
    "    wc = b[\"word_count\"]\n",
    "    is_sol = wc >= 120  # long monologues\n",
    "\n",
    "    # Scene-only speaker rule\n",
    "    sc_key = (b[\"act\"], b[\"scene\"])\n",
    "    if sc_key in scene_groups:\n",
    "        scene_spks = [x[\"speaker\"] for x in scene_groups[sc_key] if x[\"speaker\"]]\n",
    "        if len(set(scene_spks)) == 1 and b[\"speaker\"] in set(scene_spks):\n",
    "            is_sol = True\n",
    "\n",
    "    # Isolated rule (stage-direction before & after)\n",
    "    idx = blocks.index(b)\n",
    "    prev_b = blocks[idx - 1] if idx > 0 else None\n",
    "    next_b = blocks[idx + 1] if idx + 1 < len(blocks) else None\n",
    "    if (prev_b is None or prev_b[\"block_type\"] == \"stage_direction\") and \\\n",
    "       (next_b is None or next_b[\"block_type\"] == \"stage_direction\") and wc > 40:\n",
    "        is_sol = True\n",
    "\n",
    "    chunk_id += 1\n",
    "    chunks.append({\n",
    "        \"chunk_id\": chunk_id,\n",
    "        \"chunk_type\": \"speech\",\n",
    "        \"act\": b[\"act\"],\n",
    "        \"scene\": b[\"scene\"],\n",
    "        \"speaker\": b[\"speaker\"],               # EXACT AS IN step5\n",
    "        \"text\": b[\"text\"],\n",
    "        \"start_page\": b[\"start_page\"],\n",
    "        \"end_page\": b[\"end_page\"],\n",
    "        \"word_count\": wc,\n",
    "        \"is_soliloquy\": is_sol\n",
    "    })\n",
    "\n",
    "# -------------------------\n",
    "# SAVE OUTPUT FILE\n",
    "# -------------------------\n",
    "with OUT_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for c in chunks:\n",
    "        f.write(json.dumps(c, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"done → {OUT_PATH} (total chunks = {len(chunks)})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_sys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
